{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time"
      ],
      "metadata": {
        "id": "hgwy8KbknAky"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to scrape Amazon reviews\n",
        "def scrape_amazon_reviews(asin, max_pages=5):\n",
        "    base_url = f\"https://{MARKETPLACE}/product-reviews/{asin}\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "    }\n",
        "    reviews = []\n",
        "\n",
        "    for page in range(1, max_pages + 1):\n",
        "        url = f\"{base_url}?pageNumber={page}\"\n",
        "        response = requests.get(url, headers=headers)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Failed to retrieve page {page}. HTTP Status Code: {response.status_code}\")\n",
        "            break\n",
        "\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "        review_blocks = soup.find_all(\"div\", {\"data-hook\": \"review\"})\n",
        "\n",
        "        for review in review_blocks:\n",
        "            try:\n",
        "                reviewer_id = review.get(\"id\", \"N/A\")\n",
        "                reviewer_name = review.find(\"span\", {\"class\": \"a-profile-name\"}).text.strip()\n",
        "                helpful = review.find(\"span\", {\"data-hook\": \"helpful-vote-statement\"})\n",
        "                helpful = int(helpful.text.split()[0]) if helpful else 0\n",
        "                overall = float(review.find(\"i\", {\"data-hook\": \"review-star-rating\"}).text.split()[0])\n",
        "                summary = review.find(\"a\", {\"data-hook\": \"review-title\"}).text.strip()\n",
        "                unix_review_time = int(time.time())  # Simulate a Unix time\n",
        "                review_time = review.find(\"span\", {\"data-hook\": \"review-date\"}).text.strip()\n",
        "                day_diff = 0  # Placeholder: calculate difference from review_time if needed\n",
        "                helpful_yes = helpful\n",
        "                total_vote = helpful_yes  # Simplified: Adjust based on review format\n",
        "\n",
        "                reviews.append([\n",
        "                    reviewer_id,\n",
        "                    asin,\n",
        "                    reviewer_name,\n",
        "                    helpful,\n",
        "                    overall,\n",
        "                    summary,\n",
        "                    unix_review_time,\n",
        "                    review_time,\n",
        "                    day_diff,\n",
        "                    helpful_yes,\n",
        "                    total_vote,\n",
        "                ])\n",
        "            except Exception as e:\n",
        "                print(f\"Error parsing review: {e}\")\n",
        "        time.sleep(1)  # Be respectful with delay\n",
        "\n",
        "    return reviews # This line was likely misaligned. Make sure it's indented correctly."
      ],
      "metadata": {
        "id": "Ad0stIFzdZNO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save data to CSV\n",
        "def save_to_csv(data, filename=\"amazon_reviews.csv\"):\n",
        "   column_names = [\n",
        "       \"Reviewer ID\",\n",
        "       \"Asin\",\n",
        "       \"ReviewerName\",\n",
        "       \"Helpful\",\n",
        "       \"overall\",\n",
        "       \"summary\",\n",
        "       \"unixReviewTime\",\n",
        "       \"reviewTime\",\n",
        "       \"day_diff\",\n",
        "       \"helpful_yes\",\n",
        "       \"total_vote\",\n",
        "   ]\n",
        "   with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "       writer = csv.writer(file)\n",
        "       writer.writerow(column_names)\n",
        "       writer.writerows(data)\n",
        "   print(f\"Data saved to {filename}\")\n"
      ],
      "metadata": {
        "id": "xlS15kNVee3S"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "   MARKETPLACE = \"www.amazon.com\"\n",
        "   ASIN = \"B08N5WRWNW\"  # Example ASIN (replace with your own)\n",
        "\n",
        "   reviews = scrape_amazon_reviews(ASIN, max_pages=3)\n",
        "   save_to_csv(reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehtdn-EFdZhT",
        "outputId": "d9e80dcf-f176-48c4-d34d-e74e883e80b2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve page 1. HTTP Status Code: 404\n",
            "Data saved to amazon_reviews.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NLZ2eJerdZzz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AYqbVqcOdaCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRVYt48zdaQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tY8CxQ88dadv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}